{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, dataset_path: str, seq_len: int, window_size: int, rng: random.Random):\n",
    "        self.dataset = h5py.File(dataset_path, 'r')['token_ids']\n",
    "        self.seq_len = seq_len\n",
    "        self.window_size = window_size\n",
    "        self.rng = rng\n",
    "        self.size = len(self.dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self.idx):\n",
    "        start_point = self.rng.randint(0, self.size) # 0부터 self.size까지 중 랜덤\n",
    "        end_point = min(start_point + (window_size + 1), self.size) # 최소 start_point에서 window_size+1만큼 더한거부터 self.size까지\n",
    "        window = self.dataset[start_point:end_point]\n",
    "\n",
    "        input_ids = window[:-1]\n",
    "        label_ids = window[1:]\n",
    "        return input_ids, label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getitem 함수\n",
    "- start_point : 0 ~ 데이터셋 길이 사이의 임의의 시작점을 고른다.\n",
    "- end_point : 한 sample의 끝점을 고른다.\n",
    "- window : window size + 1개의 연속된 토큰을 슬라이싱한다.\n",
    "- input_ids : 첫 번째 토큰부터 window_size개 = Input Ids\n",
    "- label_ids : 두 번째 토큰부터 window_size개 = Label Ids\n",
    "\n",
    "모델에 실제로 input으로 들어가게 되는 input ids와 label ids는 (batchsize, seq_length)의 shape을 가짐<br>\n",
    "모델에는 input ids가 들어가고 출력된 logits과 label ids와 비교하게 된다.<br>\n",
    "seq_length는 window_size와 동일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def create_future_mask(x: torch.Tensor, offset: int = 0) -> torch.Tensor:\n",
    "    seq_len = x.size(-1)\n",
    "\n",
    "    # Create shifted upper triangular matrix\n",
    "    future = torch.ones((seq_len, seq_len), dtype = torch.bool, device = x.device)\n",
    "    future = future.triu(1)\n",
    "\n",
    "    future_mask = future.view((1, ) * (x.ndim - 1) + future.size())\n",
    "\n",
    "    return future_mask.expand(x.shape + future_mask.shape[-1:]) # (b, s, s) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
